{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44858,"status":"ok","timestamp":1726371019814,"user":{"displayName":"Sai Ganesh","userId":"09373529376326207367"},"user_tz":-330},"id":"efbb7_Yf5IJW","outputId":"a325a4a0-8bfc-4dd6-b5d1-db2de64e622c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pyspark\n","  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=7c0e80b68cdc15024fafc6fb3952c8b8e86800c95193bfb6d845ef3f48548fc5\n","  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.5.2\n"]}],"source":["pip install pyspark"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1006,"status":"ok","timestamp":1726371436892,"user":{"displayName":"Sai Ganesh","userId":"09373529376326207367"},"user_tz":-330},"id":"e4saehNM5iJ5","outputId":"8393a507-c86c-4d1e-ddd7-284209a33430"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------------+---------+---------------+\n","|          timestamp|device_id|energy_consumed|\n","+-------------------+---------+---------------+\n","|2024-08-26 12:00:00| device_1|            8.5|\n","|2024-08-26 11:05:00| device_2|            6.2|\n","|2024-08-26 12:10:00| device_3|            7.1|\n","|2024-08-26 10:15:00| device_4|           12.0|\n","|2024-08-26 18:20:00| device_1|            9.0|\n","|2024-08-26 12:25:00| device_2|            6.5|\n","|2024-08-26 12:30:00| device_3|            7.4|\n","|2024-08-26 20:35:00| device_4|            2.0|\n","|2024-08-26 12:40:00| device_1|            9.1|\n","|2024-08-26 23:45:00| device_2|           25.0|\n","|2024-08-26 12:50:00| device_3|            7.6|\n","|2024-08-26 22:55:00| device_4|            7.3|\n","|2024-08-26 13:00:00| device_1|            8.9|\n","|2024-08-26 13:05:00| device_2|            6.1|\n","|2024-08-26 13:10:00| device_3|            7.0|\n","|2024-08-26 18:15:00| device_4|            3.0|\n","|2024-08-26 13:20:00| device_1|           50.0|\n","|2024-08-26 13:25:00| device_2|            6.3|\n","|2024-08-26 13:30:00| device_3|            7.2|\n","|2024-08-26 19:35:00| device_4|            6.9|\n","+-------------------+---------+---------------+\n","\n"]}],"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col,window,when\n","from pyspark.sql.types import StructType,StructField,StringType,IntegerType,DoubleType,TimestampType\n","\n","spark=SparkSession.builder.appName(\"EnergyConsumptionData\").getOrCreate()\n","\n","schema=StructType([\n","      StructField(\"timestamp\",TimestampType(),True),\n","      StructField(\"device_id\",StringType(),True),\n","      StructField(\"energy_consumed\",DoubleType(),True)\n","  ])\n","\n","def process_stream(spark, schema):\n","  df=spark.read.option(\"header\",\"true\").csv(\"/content/energy_consumption_data.csv\",inferSchema=True)\n","  return df\n","\n","df=process_stream(spark,schema)\n","df.show()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1695,"status":"ok","timestamp":1726371592811,"user":{"displayName":"Sai Ganesh","userId":"09373529376326207367"},"user_tz":-330},"id":"zciEiy7qvpcY","outputId":"f6acd045-ad97-471e-d6eb-d8af2b83fa9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------------+---------+---------------+-------+\n","|          timestamp|device_id|energy_consumed|anomaly|\n","+-------------------+---------+---------------+-------+\n","|2024-08-26 10:15:00| device_4|           12.0|      1|\n","|2024-08-26 23:45:00| device_2|           25.0|      1|\n","|2024-08-26 13:20:00| device_1|           50.0|      1|\n","+-------------------+---------+---------------+-------+\n","\n","Detected anomalies saved to new csv file\n"]}],"source":["# Detecting Anomalies\n","def detect_anomalies(df, threshold=10):\n","  df_with_anomalies=df.withColumn(\"anomaly\",when(col(\"energy_consumed\")> threshold,1).otherwise(0))\n","  anomalies_df=df_with_anomalies.filter(col(\"anomaly\")==1)\n","  return anomalies_df\n","\n","anomalies_df=detect_anomalies(df,threshold=10)\n","anomalies_df.show()\n","\n","# Save the detected anomalies to a new csv file\n","anomalies_df.write.mode(\"overwrite\").csv(\"/content/anomalies_detected.csv\",header=True)\n","print(\"Detected anomalies saved to new csv file\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOY1phmfcWt92Nhwhg9D1th","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
